{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accessing appropriate pages on MediaBiasFactCheck to collect sites to visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_url = 'https://mediabiasfactcheck.com/pro-science/'\n",
    "conspiracy_url = 'https://mediabiasfactcheck.com/conspiracy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_page = requests.get(science_url, timeout=5)\n",
    "conspiracy_page = requests.get(conspiracy_url, timeout=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parsing through both pages and finding all sites that can be visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_soup = BeautifulSoup(science_page.content, 'lxml')\n",
    "science_sites = science_soup.find_all('span', {'style': 'font-size: 12pt;'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conspiracy_soup = BeautifulSoup(conspiracy_page.content, 'lxml')\n",
    "conspiracy_sites = conspiracy_soup.find_all('span', {'style': 'font-size: 12pt;'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extracting all science and conspiracy pages that can be visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will ensure request can deal with all links\n",
    "def format_links(link):\n",
    "    if not link.startswith(('https://www', \"http://www.\", \"http://\", \"https://\")):\n",
    "        if not link.startswith(('www.')):\n",
    "            link = 'www.' + link\n",
    "        if not link.startswith(('http://', 'https://')):\n",
    "            link = 'https://' + link\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db(sites):\n",
    "    db = []\n",
    "    for site in sites:\n",
    "        link = format_links(site.text[site.text.rfind('(')+1:-1])\n",
    "        source = site.text[:site.text.rfind('(')-1]\n",
    "\n",
    "        if link.count(' ') == 0 and len(source) >= 2:\n",
    "            db.append({\"name\": source, \"url\": link})    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_db = create_db(science_sites)\n",
    "conspiracy_db = create_db(conspiracy_sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Acoustics Journal',\n",
       "  'url': 'https://www.mdpi.com/journal/acoustics'},\n",
       " {'name': 'Acta Neuropathologica Communications',\n",
       "  'url': 'https://www.actaneurocomms.biomedcentral.com'},\n",
       " {'name': 'Actuators Journal',\n",
       "  'url': 'https://www.mdpi.com/journal/actuators'},\n",
       " {'name': 'Administrative Sciences Journal',\n",
       "  'url': 'https://www.mdpi.com/journal/admsci'},\n",
       " {'name': 'Adolescents Journal',\n",
       "  'url': 'https://www.mdpi.com/journal/adolescents'},\n",
       " {'name': 'Advances in Respiratory Medicine',\n",
       "  'url': 'https://www.mdpi.com/journal/arm'},\n",
       " {'name': 'Aerospace Journal',\n",
       "  'url': 'https://www.mdpi.com/journal/aerospace'},\n",
       " {'name': 'Agriculture Journal',\n",
       "  'url': 'https://www.mdpi.com/journal/agriculture'},\n",
       " {'name': 'AgriEngineering Journal',\n",
       "  'url': 'https://www.mdpi.com/journal/agriengineering'},\n",
       " {'name': 'Agrochemicals Journal',\n",
       "  'url': 'https://www.mdpi.com/journal/agrochemicals'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "science_db[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '2020ElectionCenter.c', 'url': 'https://www.2020ElectionCenter.co'},\n",
       " {'name': '21st Century Wire', 'url': 'https://www.21stcenturywire.com'},\n",
       " {'name': '79Days.Ne', 'url': 'https://www.79Days.New'},\n",
       " {'name': '369 News', 'url': 'https://www.369news.net'},\n",
       " {'name': '911Truth.org', 'url': 'https://www.911truth.org'},\n",
       " {'name': 'Above Top Secret', 'url': 'https://www.abovetopsecret.com'},\n",
       " {'name': 'A Call for an Uprising',\n",
       "  'url': 'https://www.acallforanuprising.com'},\n",
       " {'name': 'ACNLatitudes', 'url': 'https://www.latitudes.org'},\n",
       " {'name': 'Activist Post', 'url': 'https://www.activistpost.com'},\n",
       " {'name': 'Actualized.o', 'url': 'https://www.Actualized.or'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conspiracy_db[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation to ensure all links have valid headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "def is_valid_url(url):\n",
    "    try:\n",
    "        result = urlparse(url)\n",
    "        return all([result.scheme in ['http', 'https'], result.netloc])\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking if any links are not valid using the function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [is_valid_url(page['url']) for page in science_db].count(False) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [is_valid_url(page['url']) for page in conspiracy_db].count(False) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting both dbs to JSON and sending them to storage in the data/ directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_json = json.dumps(science_db, indent=4)\n",
    "conspiracy_json = json.dumps(conspiracy_db, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/extract_websites/science.json', 'w') as file:\n",
    "    file.write(science_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/extract_websites/conspiracy.json', 'w') as file:\n",
    "    file.write(conspiracy_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_acquisition code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from article_finder import ArticleFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isobarbaric/Desktop/code/projects/COVID19-Classifier/article_finder.py:56: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(page['html'], 'lxml')\n"
     ]
    }
   ],
   "source": [
    "# finding the scientific articles\n",
    "science_articles = ArticleFinder.find_articles(article_type=\"science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Sound Environment during Dental Treatment in Relation to COVID-19 Pandemic',\n",
       "  'link': 'https://www.mdpi.com/journal/acoustics/2624-599X/5/4/56'},\n",
       " {'title': 'Factors Associated with the Prevalence and Treatment of Depression in Adolescent Males in the US during the Period of the COVID-19 Pandemic',\n",
       "  'link': 'https://www.mdpi.com/journal/adolescents/2673-7051/3/4/45'},\n",
       " {'title': 'The Impact of Comprehensive Rehabilitation on the Exercise Capacity of Patients after COVID-19',\n",
       "  'link': 'https://www.mdpi.com/journal/arm/2543-6031/91/6/37'},\n",
       " {'title': 'COVID-19 Acute Respiratory Distress Syndrome: Treatment with Helmet CPAP in Respiratory Intermediate Care Unit by Pulmonologists in the Three Italian Pandemic Waves',\n",
       "  'link': 'https://www.mdpi.com/journal/arm/2543-6031/91/5/30'},\n",
       " {'title': 'The Clinical Significance of Aspergillus Detected in Lower-Respiratory-Tract Samples of Critically Ill COVID-19-Positive Patients',\n",
       "  'link': 'https://www.mdpi.com/journal/arm/2543-6031/91/5/27'},\n",
       " {'title': 'Children and COVID-19 Vaccination Trends',\n",
       "  'link': 'https://www.aap.org/en/pages/2019-novel-coronavirus-covid-19-infections/children-and-covid-19-vaccination-trends/'},\n",
       " {'title': 'COVID-19 State-Level Data Reports',\n",
       "  'link': 'https://www.aap.org/en/pages/2019-novel-coronavirus-covid-19-infections/children-and-covid-19-state-level-data-report/'},\n",
       " {'title': '\\\\n\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\n \\\\n\\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n \\\\n\\\\n\\\\n \\\\n\\\\n\\\\n\\\\t\\\\t\\\\t\\\\t \\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\tHPV Prevention\\\\n\\\\t\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\t\\\\tHuman Papillomavirus can cause 6 types of cancer. But preventing it \\\\xe2\\\\x80\\\\x94 and the cancers it causes \\\\xe2\\\\x80\\\\x94 is simple.\\\\r\\\\n\\\\n\\\\t\\\\t\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\t\\\\n\\\\t\\\\t\\\\n\\\\t',\n",
       "  'link': 'https://www.cancer.org/cancer/risk-prevention/hpv/hpv-vaccine.html'},\n",
       " {'title': 'COVID-19',\n",
       "  'link': 'https://www.lung.org/lung-health-diseases/lung-disease-lookup/covid-19'},\n",
       " {'title': \"\\\\n \\\\n End Youth Vaping\\\\n Let\\\\'s join together to end the youth vaping epidemic by supporting parents, schools and students.\\\\n \\\\n\",\n",
       "  'link': 'https://www.lung.org/quit-smoking/end-youth-vaping'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "science_articles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(science_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the conspiracy articles\n",
    "conspiracy_articles = ArticleFinder.find_articles(article_type=\"conspiracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Italian Health Minister Under Investigation for Murder for Concealing COVID-19 Vaccine Deaths',\n",
       "  'link': 'https://www.abovetopsecret.com/forum/thread1342167/pg1'},\n",
       " {'title': 'COVID vaccination rates \\\\xe2\\\\x80\\\\x98alarmingly\\\\xe2\\\\x80\\\\x99 low among nursing home staff',\n",
       "  'link': 'https://www.abovetopsecret.com/forum/thread1341843/pg1'},\n",
       " {'title': '25% of COVID Vaxxed Now Have VAIDS, Cambridge Scientists Warn',\n",
       "  'link': 'https://www.abovetopsecret.com/forum/thread1341936/pg1'},\n",
       " {'title': \"54% of US Youth are Chronically Ill* America's children are facing unprecedented epidemics! We are in a crisis\",\n",
       "  'link': 'https://childrenshealthdefense.org/follow-the-science/54-of-us-youth-are-chronically-ill/'},\n",
       " {'title': 'lobbied for COVID-19',\n",
       "  'link': 'https://www.leefang.com/p/pfizer-quietly-financed-groups-lobbying'},\n",
       " {'title': 'COVID-19',\n",
       "  'link': 'https://childrenshealthdefense.org/defender_category/covid/'},\n",
       " {'title': 'Part 6. A Pandemic Treaty and Amendments (From “The WHO\\\\xe2\\\\x80\\\\x99s Proposed Treaty Will Increase Man-Made Pandemics”)',\n",
       "  'link': 'https://ahrp.org/part-6-a-pandemic-treaty-and-amendments/'},\n",
       " {'title': 'Part 6. A Pandemic Treaty and Amendments (From \\\\xe2\\\\x80\\\\x9cThe WHO\\\\xe2\\\\x80\\\\x99s Proposed Treaty Will Increase Man-Made Pandemics\\\\xe2\\\\x80\\\\x9d)',\n",
       "  'link': 'https://ahrp.org/part-6-a-pandemic-treaty-and-amendments/'},\n",
       " {'title': 'Part 8. The Genomic Sequencing Conundrum (From “The WHO\\\\xe2\\\\x80\\\\x99s Proposed Treaty Will Increase Man-Made Pandemics”)',\n",
       "  'link': 'https://ahrp.org/part-8-the-genomic-sequencing-conundrum/'},\n",
       " {'title': 'Coronavirus Fear',\n",
       "  'link': 'https://ahrp.org/category/current-controversies/coronavirus/'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conspiracy_articles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conspiracy_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saving JSON results obtained from scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds new articles discovered to existing database (extending the database)\n",
    "def update_data(new_data, article_type):\n",
    "    def remove_dup(curr):\n",
    "        titles = set()\n",
    "        rev = []\n",
    "        for item in curr:\n",
    "            if item['title'] in titles:\n",
    "                continue\n",
    "            rev.append(item)\n",
    "            titles.add(item['title'])\n",
    "        return rev\n",
    "\n",
    "    if not (article_type == \"science\" or article_type == \"conspiracy\"):\n",
    "        raise ValueError(\"article_type param must either be 'science' or 'conspiracy'\")\n",
    "\n",
    "    with open(f\"../data/extract_articles/{article_type}.json\") as file:\n",
    "        existing_data = json.loads(file.read())\n",
    "\n",
    "    # print(len(existing_data))\n",
    "    existing_data += new_data\n",
    "    # print(len(existing_data))\n",
    "\n",
    "    with open(f\"../data/extract_articles/{article_type}.json\", 'w') as file:\n",
    "        file.write(json.dumps(remove_dup(existing_data), indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# untested after addition of update_data(), make sure to test it out\n",
    "import json\n",
    "\n",
    "# creating a function to store JSON files\n",
    "def write_articles_to_storage(article_type: str, articles: list[str]) -> None:\n",
    "    # specifying a filename where to create a new file\n",
    "    filename = f\"Data/extract_articles/{article_type}.json\"\n",
    "    update_data(articles, article_type=article_type)\n",
    "\n",
    "    # creating a new file located at filename and writing JSON-ified articles into that file\n",
    "    # with open(filename, 'w') as storage:\n",
    "    #     storage.write(json.dumps(articles, indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing the scientific and conspiracy articles found to storage for further use\n",
    "write_articles_to_storage('science', science_articles)\n",
    "write_articles_to_storage('conspiracy', conspiracy_articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid19-classifier-EHzMhhWe-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
